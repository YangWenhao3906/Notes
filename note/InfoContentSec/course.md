Kali linux系统扫描与抓包教程（仅作网络安全测试）https://www.jianshu.com/p/60b615a14d42

libpcap博客园教程 https://www.cnblogs.com/coder2012/archive/2013/04/13/3012390.html

## 系统思维和逆向思维

需求分析-三个角度

- 正常用户
- 管理者
- 攻击者

网络空间安全问题的求解的角度

- 四要素: 主体, 客体, 平台, 活动
- 五属性: 机密性, 完整性, 鉴别性, 可用性, 可控性

安全系统设计三原则:

- 区分用户
- 访问控制
- 审计



## 被动捕包流程

把网卡等同于文件进行IO

- 查找网卡: find all devices
- 打开网卡: open

从网卡中读取数据

处理获取的数据

释放IO资源



# 高性能网络流量检测

## 网络流检测模式

1. 串联监测模式:

   通过网关,网桥的模式进行监控

2. 旁路监测模式

   交换机的`端口镜像`

串联VS旁路监测:

- 旁路的优势: 部署容易, 无延时, 与现有网络分开
- 旁路的劣势: [获取]交换机需要支持端口镜像, [管控]不能禁止UDP通讯, TCP可以通过RST包的方式

### 性能提升:

- 多机并行(体系结构层面): 

  1. 分光器

  2. 粗分析
     1. 数据报 --分片重组,协议提取--> 有效载荷
     2. 特征码分析

  3. 细分析: 粗分析命中的流量分给多台机器(一对多)
     1. 病毒分析, 追踪溯源等

  - 关键: 负载均衡 eg:散列ip或url

- 提高单机能力: 捕包过程优化

  - 内存映射
  - 互斥

  |                | **被动获取** | **主动获取**             |
  | -------------- | :----------- | ------------------------ |
  | 是否需要协作   | 是           | 否                       |
  | 获取范围       | 局域网       | 因特网                   |
  | 数据处理实时性 | 实时         | 非实时                   |
  | 技术指标       | 吞吐率       | 获取效率                 |
  | 技术难点       | 不同协议处理 | web1.0, 2.0, 3.0多种获取 |



利用多处理机抓取多网站的网页信息，设计系统流程，给出任务粒度、调度算法，确保整个任务完成时间最少。

杨文昊-1190303027

**系统流程+任务粒度:**

1. 将网站根据`体量`分成两类: `大型网站`(比如GitHub等)、`中小型网站`(比如哈工大网站等). 
   - 完成此步骤需要事前构建`大型网站的URL库`
   - 当然, 此处的体量也是相对于自己的带宽、处理能力等而言的
2. 首先, 抓取大型网站, 采用`轻者启动`完成抓取, 任务粒度为`页面`
3. 然后, 抓取中小型网站, 采用`重者启动`完成抓取, 任务粒度为`网站`

解释: 轻者启动, 基本能做到同时结束; 而中小型网站由于体量不算大, 重者启动, 也能达到比较高的并行度, 而且通讯次数更少



**调度算法:**

1. 重者启动:

```c
// 进行各个网站的分配
DS:
Url_QUEUE   uqueue;
PROCEDURE:
Crawler（seed_url）                            // seed_url是起始URL队列集合
{   in_queue (uqueue , seed_url);  
 	// 进行各个网站的分配
    while  （u=out_queue(uqueue) ）            //从uqueue队列中移除url地址
    {
        n=hash（u） mod  N;   // N为节点机总个数
        if  (n==my_node_ID)
        	then in_queue (uqueue , u); 
        else  sendurl(u,n);   // 将url发到节点机n，并插入到n的uqueue
     }
}
```

2. 轻者启动: 

```c
DS：// 与讲义中的多机协同抓取算法基本相同
Url_QUEUE   uqueue;
History_LIST  hlist;
PROCEDURE:
Crawler（big_url）                            // seed_url是起始URL队列集合
{   in_queue (uqueue , big_url);                       
    while  （u=out_queue(uqueue) ）            //从uqueue队列中移除url地址
    {
       wpage=http_get(u);                      // 下载网页
       save wpage;                            // 保存网页
       for each url in wpage                     // 解析网页中的URL，看是否被访问过
            { if  url not in hlist  
              then{
                      n=hash（url ） mod  N;   // N为节点机总个数
                    if  (n==my_node_ID)
                      then in_queue (uqueue , url); 
                           else  sendurl(url,n);   // 将url发到节点机n，并插入到n的uqueue
                     } 
            }     // 未被访问加入到uqueue队列中
     }
}
```

内心好矛盾啊

和ta在一起的第一周, 我发现ta真的好爱我. 即使卑微如我, 居然

经历那一周的

3月14日那天, 我甚至希望ta对我说再见
